{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/usr/local/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ['THEANO_FLAGS']='mode=FAST_RUN,device=' + device + ',floatX=float32,nvcc.flags=-D_FORCE_INLINES'\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import datetime\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import cPickle # for saving scaler and labelencoder\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd # Pandas for easier Data handling in preparation\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import ShuffleSplit, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from theano import config\n",
    "from theano import function as tfunction\n",
    "\n",
    "import keras\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.callbacks import Callback, History, EarlyStopping, ModelCheckpoint # BaseLogger,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "RANDOM_SEED = 2107\n",
    "\n",
    "\n",
    "# adapted from https://github.com/fchollet/keras/blob/master/keras/applications/imagenet_utils.py\n",
    "# (skipping 0 mean as we do this separately)\n",
    "\n",
    "def reorder_RGB(data, dim_ordering='default'):\n",
    "    if dim_ordering == 'default':\n",
    "        dim_ordering = 'th' #K.image_dim_ordering()\n",
    "    assert dim_ordering in {'tf', 'th'}\n",
    "\n",
    "    # reorder 'RGB'->'BGR' according to Theano or Tensorflow order\n",
    "    if dim_ordering == 'th':\n",
    "        data = data[:, ::-1, :, :]\n",
    "    else:\n",
    "        data = data[:, :, :, ::-1]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# STANDARDIZE DATA\n",
    "\n",
    "def standardize(data, return_scaler = True, copy=True):\n",
    "    '''standardize the data with zero mean unit variance (feature attribute-wise)\n",
    "\n",
    "    data: numpy array to be transformed\n",
    "    return_scaler: if True, a tuple of (data, scaler) will be returned with the scaler object containing all necessary parameters to scale other data again\n",
    "    copy = False means try to avoid a copy and do inplace scaling instead.\n",
    "    '''\n",
    "\n",
    "    if return_scaler:\n",
    "        # STANDARDIZATION (0 mean, unit var)\n",
    "        scaler = preprocessing.StandardScaler(copy)\n",
    "        # alternative: NORMALIZATION (min - max Normalization to (0,1))\n",
    "        #scaler = preprocessing.MinMaxScaler()\n",
    "        data = scaler.fit_transform(data)\n",
    "        return (data, scaler)\n",
    "    else:\n",
    "        return preprocessing.scale(data,axis=0,copy=copy)\n",
    "        # axis=0 means independently standardize each feature, otherwise (if 1) standardize each sample\n",
    "\n",
    "    # how to get scaler parameters:\n",
    "    #print scaler.mean_\n",
    "    #print scaler.scale_\n",
    "\n",
    "\n",
    "def standardize_flat(data):\n",
    "    from scipy.stats.mstats import zscore\n",
    "    return zscore(data,axis=None)\n",
    "    # the manual version:\n",
    "    #m = np.mean(a)\n",
    "    #s = np.std(a)\n",
    "    #(a - m) / s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # settings\n",
    "    PATH = '/data/images/monds-persondetect-7k'  # base path\n",
    "    csv_file = os.path.join(PATH, 'labels.csv')\n",
    "    thumbs_path = os.path.join(PATH, 'thumbs')\n",
    "\n",
    "    size = 224\n",
    "    file = \"mon_style_persons_cropped_resized_%dx%d.npz\" % (size, size)\n",
    "    img_thumb_file = os.path.join(thumbs_path, file)\n",
    "\n",
    "    folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7833 images with size (224, 224) and 3 color channels\n"
     ]
    }
   ],
   "source": [
    "    # load meta-data\n",
    "\n",
    "    image_list = pd.read_csv(csv_file)\n",
    "    image_files = list(image_list.image)\n",
    "    groundtruth = list(image_list.person)\n",
    "\n",
    "    # load image data\n",
    "    data = np.load(img_thumb_file)\n",
    "    images = data['images']\n",
    "    file_ids = data['filenames']\n",
    "    data.close() #  the returned instance of NpzFile class must be closed to avoid leaking file descriptors\n",
    "    \n",
    "    # dimensions\n",
    "    n_images = images.shape[0]\n",
    "    img_size = images.shape[1:3]\n",
    "    n_channels = images.shape[3]\n",
    "    #images.shape\n",
    "    \n",
    "    print \"Loaded\", images.shape[0], \"images with size\", img_size, \"and\", n_channels, \"color channels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # re-sort groundtruth by file_ids order from image thumbs file\n",
    "    groundtruth_df = pd.DataFrame(groundtruth, index=image_files) # make dataframe\n",
    "    groundtruth_df = groundtruth_df.ix[file_ids]\n",
    "    groundtruth = groundtruth_df[0].values # is now np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_list = list(groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundtruth Statistics:\n",
      "Class 0 : 2164\n",
      "Class 1 : 5669\n"
     ]
    }
   ],
   "source": [
    "print \"Groundtruth Statistics:\"\n",
    "#class_counts = \n",
    "for v in set(gt_list):\n",
    "    print \"Class\", v, \":\", gt_list.count(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7237329248053108"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = 5669 * 1.0 / len(gt_list)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# needed? dont think so\n",
    "#groundtruth=groundtruth.astype(config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7833, 3, 224, 224)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # reorder data\n",
    "\n",
    "    # color channel is the last axis in input images, we move it to axis 1\n",
    "    # TODO check if this doesnt rotate the image - i think it does\n",
    "    images = np.swapaxes(images,1,3)\n",
    "    images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7833, 3, 224, 224)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # TODO why is this done (e.g. in ResNet 50)\n",
    "    # TODO this depends on Theano vs Keras: change Code above to incorporate K.image_dim_ordering()\n",
    "    images = reorder_RGB(images, dim_ordering='default') \n",
    "    images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.min(), images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = images.astype(config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186.14\n",
      "188.196\n",
      "194.957\n"
     ]
    }
   ],
   "source": [
    "# standardize each RGB channel - inspired from keras ResNet50 / image_util preprocess\n",
    "\n",
    "x = images\n",
    "\n",
    "for c in range(3):\n",
    "    print x[:, c, :, :].mean()\n",
    "    x[:, c, :, :] -= x[:, c, :, :].mean()\n",
    "    x[:, c, :, :] /= x[:, c, :, :].std() # was not in ResNet implementation\n",
    "\n",
    "images = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.5346594, 0.86231875)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.min(), images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-72a207e1f4d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# TODO verify if the data order is right for this standardization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# TODO also check whether we need to standardize each channel separately\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-1b388479fe6d>\u001b[0m in \u001b[0;36mstandardize_flat\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mstandardize_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mzscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;31m# the manual version:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m#m = np.mean(a)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/stats/stats.pyc\u001b[0m in \u001b[0;36mzscore\u001b[1;34m(a, axis, ddof)\u001b[0m\n\u001b[0;32m   2034\u001b[0m                  np.expand_dims(sstd,axis=axis))\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2036\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0msstd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    # standardize FLAT\n",
    "    # TODO verify which kind of standardization we need\n",
    "    # TODO verify if the data order is right for this standardization\n",
    "    # TODO also check whether we need to standardize each channel separately\n",
    "    images = standardize_flat(images)\n",
    "    images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# standardize flat myself\n",
    "images -= np.mean(images, axis=0) # 0 center\n",
    "images /= np.std(images, axis=0)  # normalize by stdev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-279.01828, 41.362053)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.min(), images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.7521609e-06"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # create folds\n",
    "    splits = StratifiedKFold(groundtruth, n_folds=folds, shuffle=True, random_state=RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 5221 Test: 2612\n",
      "Train: 5222 Test: 2611\n",
      "Train: 5223 Test: 2610\n"
     ]
    }
   ],
   "source": [
    "    for train_ind, test_ind in splits:\n",
    "        print \"Train:\", len(train_ind), \"Test:\", len(test_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_img = images[train_ind]\n",
    "test_img = images[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gt = groundtruth[train_ind]\n",
    "test_gt = groundtruth[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5223,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5223, 3, 224, 224)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gt.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = images.shape[1:]\n",
    "output_units = 1\n",
    "\n",
    "multi_class = output_units > 1\n",
    "multi_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras 0.3\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten # Reshape,\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D # CNN\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras 1.x\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# taking just one channel for full model\n",
    "imagesch1 = images[:,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_flat = images.reshape(images.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_img = images_flat[train_ind]\n",
    "test_img = images_flat[test_ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_shape = (images_flat.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simple Full network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_dim=input_shape))\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simple CNN to test\n",
    "\n",
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> input_shape should be (3, 100, 100) \n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=input_shape))\n",
    "#model.add(Activation('relu')) # WAS COMMENTED OUT WHEN WORKED\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2))) # NEW\n",
    "#model.add(Dropout(0.1)) # NEW\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Note: Keras does automatic shape inference.\n",
    "model.add(Dense(256))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "if output_units > 1:\n",
    "    model.add(Dense(output_units))\n",
    "    model.add(Activation('softmax'))\n",
    "else:\n",
    "    model.add(Dense(1,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# VGG-like convnet:\n",
    "# (from https://keras.io/getting-started/sequential-model-guide/)\n",
    "\n",
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> input_shape should be (3, 100, 100) \n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Note: Keras does automatic shape inference.\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "if output_units > 1:\n",
    "    model.add(Dense(output_units))\n",
    "    model.add(Activation('softmax'))\n",
    "else:\n",
    "    model.add(Dense(1,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Initial input shape: (None, 3, 224, 224)\n",
      "--------------------------------------------------------------------------------\n",
      "Layer (name)                  Output Shape                  Param #             \n",
      "--------------------------------------------------------------------------------\n",
      "Convolution2D (Unnamed)       (None, 32, 222, 222)          896                 \n",
      "Activation (Unnamed)          (None, 32, 222, 222)          0                   \n",
      "Convolution2D (Unnamed)       (None, 32, 220, 220)          9248                \n",
      "Activation (Unnamed)          (None, 32, 220, 220)          0                   \n",
      "MaxPooling2D (Unnamed)        (None, 32, 110, 110)          0                   \n",
      "Dropout (Unnamed)             (None, 32, 110, 110)          0                   \n",
      "Convolution2D (Unnamed)       (None, 64, 108, 108)          18496               \n",
      "Activation (Unnamed)          (None, 64, 108, 108)          0                   \n",
      "Convolution2D (Unnamed)       (None, 64, 106, 106)          36928               \n",
      "Activation (Unnamed)          (None, 64, 106, 106)          0                   \n",
      "MaxPooling2D (Unnamed)        (None, 64, 53, 53)            0                   \n",
      "Dropout (Unnamed)             (None, 64, 53, 53)            0                   \n",
      "Flatten (Unnamed)             (None, 179776)                0                   \n",
      "Dense (Unnamed)               (None, 256)                   46022912            \n",
      "Activation (Unnamed)          (None, 256)                   0                   \n",
      "Dropout (Unnamed)             (None, 256)                   0                   \n",
      "Dense (Unnamed)               (None, 1)                     257                 \n",
      "--------------------------------------------------------------------------------\n",
      "Total params: 46088737\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we use test data as validation data to see direct results (usually not recommended)\n",
    "validation_data = (test_img, test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mode: binary , multi_class: False\n"
     ]
    }
   ],
   "source": [
    "if multi_class:\n",
    "    loss = 'categorical_crossentropy' # multi class\n",
    "    class_mode='categorical'\n",
    "    #optimizer = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # try simpler first\n",
    "    optimizer = SGD(lr=0.001)\n",
    "else: # binary 0/1\n",
    "    loss = 'binary_crossentropy' \n",
    "    class_mode='binary'\n",
    "    optimizer = 'rmsprop'\n",
    "    #optimizer = RMSprop(lr=0.0001)\n",
    "    #optimizer = 'adam'\n",
    "    #optimizer = SGD(lr=0.001)\n",
    "\n",
    "print \"Class mode:\", class_mode, \", multi_class:\", multi_class\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, class_mode=class_mode)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5223 samples, validate on 2610 samples\n",
      "Epoch 1/5\n",
      "5223/5223 [==============================] - 49s - loss: 2.9302 - acc: 0.7551 - val_loss: 1.3788 - val_acc: 0.7360\n",
      "Epoch 2/5\n",
      "5223/5223 [==============================] - 52s - loss: 0.3937 - acc: 0.8878 - val_loss: 0.2455 - val_acc: 0.9330\n",
      "Epoch 3/5\n",
      "5223/5223 [==============================] - 52s - loss: 0.2262 - acc: 0.9349 - val_loss: 0.2068 - val_acc: 0.9138\n",
      "Epoch 4/5\n",
      "3168/5223 [=================>............] - ETA: 18s - loss: 0.1428 - acc: 0.9602"
     ]
    }
   ],
   "source": [
    "    epochs = 5\n",
    "    model.fit(train_img, train_gt, batch_size=32, nb_epoch=epochs, validation_data=validation_data, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5223/5223 [==============================] - 8s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72372199885123489"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify Accuracy on Train set\n",
    "train_pred = model.predict_classes(train_img)\n",
    "accuracy_score(train_gt, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610/2610 [==============================] - 4s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72375478927203063"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTING\n",
    "test_pred = model.predict_classes(test_img)\n",
    "acc = accuracy_score(test_gt, test_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
