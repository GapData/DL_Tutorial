{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Recognition with Deep Learning\n",
    "\n",
    "This tutorial shows how Deep Neural Networks are used to recognize cars on images versus images with no cars on them (binary classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['THEANO_FLAGS']='mode=FAST_RUN,device=' + device + ',floatX=float32,nvcc.flags=-D_FORCE_INLINES'\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd # Pandas for easier Data handling in preparation\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import ShuffleSplit, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from theano import config\n",
    "from theano import function as tfunction\n",
    "\n",
    "import keras\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from progressbar import ProgressBar\n",
    "# needed?\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import Callback, History, EarlyStopping, ModelCheckpoint # BaseLogger,\n",
    "\n",
    "import json\n",
    "#import cPickle # for saving scaler and labelencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "RANDOM_SEED = 2107\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Images from Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1050 files\n"
     ]
    }
   ],
   "source": [
    "path = 'data/CarData/TrainImages'\n",
    "files = glob.glob(os.path.join(path, '*.pgm'))\n",
    "print \"Found\", len(files), \"files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "image_names = []\n",
    "\n",
    "for filename in files:\n",
    "    image_names.append(os.path.basename(filename))\n",
    "    #img = Image.open(filename)\n",
    "    with Image.open(filename) as img:\n",
    "        images.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg-85.pgm\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAAAoCAAAAAAtEwCfAAANE0lEQVR4nAXBeYwd9X0A8O/85veb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\ngNhQNyzRowknQGyHc29s8EbYXfx/YFZwQLvICJIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x40 at 0x7F482D652B10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "print image_names[i]\n",
    "Image.fromarray(images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 100)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[i].shape   # height x width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Color RGB images have an additional dimension of depth 3, e.g. (40, 100, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make 1 big array of list of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 40, 100)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array = np.array(images)\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Groundtruth based on filenames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = []\n",
    "for name in image_names:\n",
    "    if name.startswith('neg'):\n",
    "        classes.append(0)\n",
    "    else:\n",
    "        classes.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# STANDARDIZE DATA\n",
    "\n",
    "def standardize(data, return_scaler = True, copy=True):\n",
    "    '''standardize the data with zero mean unit variance (feature attribute-wise)\n",
    "\n",
    "    data: numpy array to be transformed\n",
    "    return_scaler: if True, a tuple of (data, scaler) will be returned with the scaler object containing all necessary parameters to scale other data again\n",
    "    copy = False means try to avoid a copy and do inplace scaling instead.\n",
    "    '''\n",
    "\n",
    "    if return_scaler:\n",
    "        # STANDARDIZATION (0 mean, unit var)\n",
    "        scaler = preprocessing.StandardScaler(copy)\n",
    "        # alternative: NORMALIZATION (min - max Normalization to (0,1))\n",
    "        #scaler = preprocessing.MinMaxScaler()\n",
    "        data = scaler.fit_transform(data)\n",
    "        return (data, scaler)\n",
    "    else:\n",
    "        return preprocessing.scale(data,axis=0,copy=copy)\n",
    "        # axis=0 means independently standardize each feature, otherwise (if 1) standardize each sample\n",
    "\n",
    "    # how to get scaler parameters:\n",
    "    #print scaler.mean_\n",
    "    #print scaler.scale_\n",
    "\n",
    "\n",
    "def standardize_flat(data):\n",
    "    from scipy.stats.mstats import zscore\n",
    "    return zscore(data,axis=None)\n",
    "    # the manual version:\n",
    "    #m = np.mean(a)\n",
    "    #s = np.std(a)\n",
    "    #(a - m) / s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundtruth Statistics:\n",
      "Class 0 : 500\n",
      "Class 1 : 550\n"
     ]
    }
   ],
   "source": [
    "print \"Groundtruth Statistics:\"\n",
    "#class_counts = \n",
    "for v in set(classes):\n",
    "    print \"Class\", v, \":\", classes.count(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5238095238095238"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = 550 * 1.0 / len(classes)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7833, 3, 224, 224)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # reorder data\n",
    "\n",
    "    # color channel is the last axis in input images, we move it to axis 1\n",
    "    # TODO check if this doesnt rotate the image - i think it does\n",
    "    images = np.swapaxes(images,1,3)\n",
    "    images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7833, 3, 224, 224)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # TODO why is this done (e.g. in ResNet 50)\n",
    "    # TODO this depends on Theano vs Keras: change Code above to incorporate K.image_dim_ordering()\n",
    "    images = reorder_RGB(images, dim_ordering='default') \n",
    "    images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.min(), images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = images.astype(config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186.14\n",
      "188.196\n",
      "194.957\n"
     ]
    }
   ],
   "source": [
    "# standardize each RGB channel - inspired from keras ResNet50 / image_util preprocess\n",
    "\n",
    "x = images\n",
    "\n",
    "for c in range(3):\n",
    "    print x[:, c, :, :].mean()\n",
    "    x[:, c, :, :] -= x[:, c, :, :].mean()\n",
    "    x[:, c, :, :] /= x[:, c, :, :].std() # was not in ResNet implementation\n",
    "\n",
    "images = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.5346594, 0.86231875)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.min(), images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-72a207e1f4d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# TODO verify if the data order is right for this standardization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# TODO also check whether we need to standardize each channel separately\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-1b388479fe6d>\u001b[0m in \u001b[0;36mstandardize_flat\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mstandardize_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mzscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;31m# the manual version:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m#m = np.mean(a)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/stats/stats.pyc\u001b[0m in \u001b[0;36mzscore\u001b[1;34m(a, axis, ddof)\u001b[0m\n\u001b[0;32m   2034\u001b[0m                  np.expand_dims(sstd,axis=axis))\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2036\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0msstd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    # standardize FLAT\n",
    "    # TODO verify which kind of standardization we need\n",
    "    # TODO verify if the data order is right for this standardization\n",
    "    # TODO also check whether we need to standardize each channel separately\n",
    "    images = standardize_flat(images)\n",
    "    images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# standardize flat myself\n",
    "images -= np.mean(images, axis=0) # 0 center\n",
    "images /= np.std(images, axis=0)  # normalize by stdev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-279.01828, 41.362053)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.min(), images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.7521609e-06"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # create folds\n",
    "    splits = StratifiedKFold(groundtruth, n_folds=folds, shuffle=True, random_state=RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 5221 Test: 2612\n",
      "Train: 5222 Test: 2611\n",
      "Train: 5223 Test: 2610\n"
     ]
    }
   ],
   "source": [
    "    for train_ind, test_ind in splits:\n",
    "        print \"Train:\", len(train_ind), \"Test:\", len(test_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_img = images[train_ind]\n",
    "test_img = images[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gt = groundtruth[train_ind]\n",
    "test_gt = groundtruth[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5223,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5223, 3, 224, 224)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gt.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = images.shape[1:]\n",
    "output_units = 1\n",
    "\n",
    "multi_class = output_units > 1\n",
    "multi_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras 0.3\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten # Reshape,\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D # CNN\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras 1.x\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# taking just one channel for full model\n",
    "imagesch1 = images[:,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_flat = images.reshape(images.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_img = images_flat[train_ind]\n",
    "test_img = images_flat[test_ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_shape = (images_flat.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simple Full network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_dim=input_shape))\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simple CNN to test\n",
    "\n",
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> input_shape should be (3, 100, 100) \n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=input_shape))\n",
    "#model.add(Activation('relu')) # WAS COMMENTED OUT WHEN WORKED\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2))) # NEW\n",
    "#model.add(Dropout(0.1)) # NEW\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Note: Keras does automatic shape inference.\n",
    "model.add(Dense(256))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "if output_units > 1:\n",
    "    model.add(Dense(output_units))\n",
    "    model.add(Activation('softmax'))\n",
    "else:\n",
    "    model.add(Dense(1,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# VGG-like convnet:\n",
    "# (from https://keras.io/getting-started/sequential-model-guide/)\n",
    "\n",
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> input_shape should be (3, 100, 100) \n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Note: Keras does automatic shape inference.\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "if output_units > 1:\n",
    "    model.add(Dense(output_units))\n",
    "    model.add(Activation('softmax'))\n",
    "else:\n",
    "    model.add(Dense(1,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Initial input shape: (None, 3, 224, 224)\n",
      "--------------------------------------------------------------------------------\n",
      "Layer (name)                  Output Shape                  Param #             \n",
      "--------------------------------------------------------------------------------\n",
      "Convolution2D (Unnamed)       (None, 32, 222, 222)          896                 \n",
      "Activation (Unnamed)          (None, 32, 222, 222)          0                   \n",
      "Convolution2D (Unnamed)       (None, 32, 220, 220)          9248                \n",
      "Activation (Unnamed)          (None, 32, 220, 220)          0                   \n",
      "MaxPooling2D (Unnamed)        (None, 32, 110, 110)          0                   \n",
      "Dropout (Unnamed)             (None, 32, 110, 110)          0                   \n",
      "Convolution2D (Unnamed)       (None, 64, 108, 108)          18496               \n",
      "Activation (Unnamed)          (None, 64, 108, 108)          0                   \n",
      "Convolution2D (Unnamed)       (None, 64, 106, 106)          36928               \n",
      "Activation (Unnamed)          (None, 64, 106, 106)          0                   \n",
      "MaxPooling2D (Unnamed)        (None, 64, 53, 53)            0                   \n",
      "Dropout (Unnamed)             (None, 64, 53, 53)            0                   \n",
      "Flatten (Unnamed)             (None, 179776)                0                   \n",
      "Dense (Unnamed)               (None, 256)                   46022912            \n",
      "Activation (Unnamed)          (None, 256)                   0                   \n",
      "Dropout (Unnamed)             (None, 256)                   0                   \n",
      "Dense (Unnamed)               (None, 1)                     257                 \n",
      "--------------------------------------------------------------------------------\n",
      "Total params: 46088737\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we use test data as validation data to see direct results (usually not recommended)\n",
    "validation_data = (test_img, test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mode: binary , multi_class: False\n"
     ]
    }
   ],
   "source": [
    "if multi_class:\n",
    "    loss = 'categorical_crossentropy' # multi class\n",
    "    class_mode='categorical'\n",
    "    #optimizer = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # try simpler first\n",
    "    optimizer = SGD(lr=0.001)\n",
    "else: # binary 0/1\n",
    "    loss = 'binary_crossentropy' \n",
    "    class_mode='binary'\n",
    "    optimizer = 'rmsprop'\n",
    "    #optimizer = RMSprop(lr=0.0001)\n",
    "    #optimizer = 'adam'\n",
    "    #optimizer = SGD(lr=0.001)\n",
    "\n",
    "print \"Class mode:\", class_mode, \", multi_class:\", multi_class\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, class_mode=class_mode)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5223 samples, validate on 2610 samples\n",
      "Epoch 1/5\n",
      "5223/5223 [==============================] - 49s - loss: 2.9302 - acc: 0.7551 - val_loss: 1.3788 - val_acc: 0.7360\n",
      "Epoch 2/5\n",
      "5223/5223 [==============================] - 52s - loss: 0.3937 - acc: 0.8878 - val_loss: 0.2455 - val_acc: 0.9330\n",
      "Epoch 3/5\n",
      "5223/5223 [==============================] - 52s - loss: 0.2262 - acc: 0.9349 - val_loss: 0.2068 - val_acc: 0.9138\n",
      "Epoch 4/5\n",
      "3168/5223 [=================>............] - ETA: 18s - loss: 0.1428 - acc: 0.9602"
     ]
    }
   ],
   "source": [
    "    epochs = 5\n",
    "    model.fit(train_img, train_gt, batch_size=32, nb_epoch=epochs, validation_data=validation_data, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5223/5223 [==============================] - 8s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72372199885123489"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify Accuracy on Train set\n",
    "train_pred = model.predict_classes(train_img)\n",
    "accuracy_score(train_gt, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610/2610 [==============================] - 4s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72375478927203063"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTING\n",
    "test_pred = model.predict_classes(test_img)\n",
    "acc = accuracy_score(test_gt, test_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
