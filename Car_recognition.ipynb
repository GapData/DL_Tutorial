{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Recognition with Deep Learning\n",
    "\n",
    "This tutorial shows how Deep Neural Networks are used to recognize cars on images versus images with no cars on them (binary classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ['THEANO_FLAGS']='mode=FAST_RUN,device=' + device + ',floatX=float32,nvcc.flags=-D_FORCE_INLINES'\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from theano import config\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import ShuffleSplit, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# needed?\n",
    "import keras\n",
    "\n",
    "import pandas as pd # Pandas for easier Data handling in preparation\n",
    "\n",
    "from theano import function as tfunction\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import Callback, History, EarlyStopping, ModelCheckpoint # BaseLogger,\n",
    "\n",
    "import json\n",
    "#import cPickle # for saving scaler and labelencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Images from Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1050 files\n"
     ]
    }
   ],
   "source": [
    "path = 'data/CarData/TrainImages'\n",
    "files = glob.glob(os.path.join(path, '*.pgm'))\n",
    "print \"Found\", len(files), \"files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "image_names = []\n",
    "\n",
    "for filename in files:\n",
    "    image_names.append(os.path.basename(filename))\n",
    "    with Image.open(filename) as img:\n",
    "        images.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg-102.pgm\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAAAoCAAAAAAtEwCfAAAMVElEQVR4nAXBWYyd110A8P/5n+Vb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\nfyU+30l4IOjDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x40 at 0x11ADF3F90>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=5\n",
    "print image_names[i]\n",
    "Image.fromarray(images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 100)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[i].shape   # height x width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Color RGB images have an additional dimension of depth 3, e.g. (40, 100, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make 1 big array of list of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 40, 100)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of many 40x100 images is made into 1 big array\n",
    "# config.floatX is from Theano configration to enforce float32 precision (needed for GPU computation)\n",
    "img_array = np.array(images, dtype=config.floatX)\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Groundtruth based on filenames:\n",
    "\n",
    "In this data set, images with cars start with \"pos-\" and images with no cars start with \"neg-\". We create a numeric list here containing 1 for car images and 0 for non-car images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = []\n",
    "for name in image_names:\n",
    "    if name.startswith('neg'):\n",
    "        classes.append(0)\n",
    "    else:\n",
    "        classes.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundtruth Statistics:\n",
      "Class 0 : 500\n",
      "Class 1 : 550\n"
     ]
    }
   ],
   "source": [
    "print \"Groundtruth Statistics:\"\n",
    "\n",
    "for v in set(classes):\n",
    "    print \"Class\", v, \":\", classes.count(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5238095238095238"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = 550 * 1.0 / len(classes)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "\n",
    "<b>Always standardize</b> the data before feeding it into the Neural Network!\n",
    "\n",
    "Here we use <b>Zero-mean Unit-variance standardization</b> (flat, i.e. one mean and std.dev. for the whole image is computed over all pixels; in RGB images, standardization can be done e.g. for each colour channel individually; in other/non-image data sets, attribute-wise standardization should be applied)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129.582 74.2767\n"
     ]
    }
   ],
   "source": [
    "mean = img_array.mean()\n",
    "stddev = img_array.std()\n",
    "print mean, stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.29858e-07 1.0\n"
     ]
    }
   ],
   "source": [
    "img_array = (img_array - mean) / stddev\n",
    "print img_array.mean(), img_array.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.7445902, 1.6885179)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.min(), img_array.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# create folds\n",
    "folds = 3\n",
    "splits = StratifiedKFold(classes, n_folds=folds, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    for train_ind, test_ind in splits:\n",
    "        print \"Train:\", len(train_ind), \"Test:\", len(test_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_img = images[train_ind]\n",
    "test_img = images[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gt = groundtruth[train_ind]\n",
    "test_gt = groundtruth[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = images.shape[1:]\n",
    "output_units = 1\n",
    "\n",
    "multi_class = output_units > 1\n",
    "multi_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating NN Models in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1) Fully Connected NN\n",
    "\n",
    "For a fully connected neural network, the images have to be flattened, as the x and y axis do not play a role. All pixels are considered as a completely individual input to the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 4000)\n"
     ]
    }
   ],
   "source": [
    "#  flatten images to vectors\n",
    "images_flat = img_array.reshape(img_array.shape[0],-1)\n",
    "print images_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "# find out input shape for NN, which is just a long vector (40x100 = 4000)\n",
    "input_shape = images_flat.shape[1]\n",
    "print input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Model\n",
    "\n",
    "In Keras, one can choose between a Sequential model and a Graph model. Sequential models are the standard case. Graph models are for parallel networks.\n",
    "\n",
    "Here we create a sequential model with 2 fully connected (a.k.a. 'dense') layers containing 256 units each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simple Fully-connected network\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_dim=input_shape))\n",
    "\n",
    "model.add(Dense(256))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_4 (Dense)                  (None, 256)           1024256     dense_input_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 256)           65792       dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1)             257         dense_5[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,090,305\n",
      "Trainable params: 1,090,305\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preparing / compiling the model\n",
    "loss = 'binary_crossentropy' \n",
    "optimizer = 'sgd' #rmsprop'\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model on the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1050 samples, validate on 170 samples\n",
      "Epoch 1/15\n",
      "1050/1050 [==============================] - 0s - loss: 0.5130 - acc: 0.7933 - val_loss: 4.3284 - val_acc: 0.0059\n",
      "Epoch 2/15\n",
      "1050/1050 [==============================] - 0s - loss: 0.3198 - acc: 0.8505 - val_loss: 1.2280 - val_acc: 0.4588\n",
      "Epoch 3/15\n",
      "1050/1050 [==============================] - 0s - loss: 0.2163 - acc: 0.9143 - val_loss: 2.1355 - val_acc: 0.2294\n",
      "Epoch 4/15\n",
      "1050/1050 [==============================] - 0s - loss: 0.1779 - acc: 0.9314 - val_loss: 1.7259 - val_acc: 0.3706\n",
      "Epoch 5/15\n",
      "1050/1050 [==============================] - 0s - loss: 0.1400 - acc: 0.9562 - val_loss: 2.3594 - val_acc: 0.2235\n",
      "Epoch 6/15\n",
      "1050/1050 [==============================] - 0s - loss: 0.1214 - acc: 0.9543 - val_loss: 1.5213 - val_acc: 0.4176\n",
      "Epoch 7/15\n",
      "1050/1050 [==============================] - 0s - loss: 0.1040 - acc: 0.9714 - val_loss: 1.3257 - val_acc: 0.4941\n",
      "Epoch 8/15\n",
      "1050/1050 [==============================] - 0s - loss: 0.0763 - acc: 0.9848 - val_loss: 2.7606 - val_acc: 0.1882\n",
      "Epoch 9/15\n",
      "1050/1050 [==============================] - 0s - loss: 0.0825 - acc: 0.9752 - val_loss: 2.2161 - val_acc: 0.2941\n",
      "Epoch 10/15\n",
      "1050/1050 [==============================] - 0s - loss: 0.0555 - acc: 0.9914 - val_loss: 2.3047 - val_acc: 0.3529\n",
      "Epoch 11/15\n",
      "1050/1050 [==============================] - 0s - loss: 0.0496 - acc: 0.9924 - val_loss: 2.2905 - val_acc: 0.3294\n",
      "Epoch 12/15\n",
      "1050/1050 [==============================] - 0s - loss: 0.0417 - acc: 0.9962 - val_loss: 1.9341 - val_acc: 0.4118\n",
      "Epoch 13/15\n",
      "1050/1050 [==============================] - 0s - loss: 0.0334 - acc: 0.9990 - val_loss: 2.4412 - val_acc: 0.3294\n",
      "Epoch 14/15\n",
      "1050/1050 [==============================] - 0s - loss: 0.0300 - acc: 0.9990 - val_loss: 2.5472 - val_acc: 0.3294\n",
      "Epoch 15/15\n",
      "1050/1050 [==============================] - 0s - loss: 0.0269 - acc: 1.0000 - val_loss: 2.5923 - val_acc: 0.3176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b411750>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 15\n",
    "model.fit(images_flat, classes, batch_size=32, nb_epoch=epochs) #, validation_data=validation_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 960/1050 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify Accuracy on Train set\n",
    "predictions = model.predict_classes(images_flat)\n",
    "accuracy_score(predictions, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100% Accuracy - perfect, no?\n",
    "\n",
    "This is the accuracy on the training set. A (large, especially fully connected network with sufficient number of units) can easily learn the entire training set (especially a small one like here).\n",
    "\n",
    "This very likely leads to <b>overfitting</b>. That's why we test on an independent test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 170 files\n"
     ]
    }
   ],
   "source": [
    "path = 'data/CarData/TestImages'\n",
    "files = glob.glob(os.path.join(path, '*.pgm'))\n",
    "print \"Found\", len(files), \"files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from image_preprocessing import resize_and_crop\n",
    "\n",
    "test_images = []\n",
    "\n",
    "for filename in files:\n",
    "    with Image.open(filename) as img:\n",
    "        img_resized = resize_and_crop(img,target_width=100,target_height=40)\n",
    "        test_images.append(np.array(img_resized))\n",
    "        #print img.size, img_resized.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAAAoCAAAAAAtEwCfAAAKEklEQVR4nH3W2Y+d510H8Gd91/O+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\nLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x40 at 0x118CAB850>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "Image.fromarray(test_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make 1 big array again from list\n",
    "test_images = np.array(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Test Set\n",
    "\n",
    "The test data has to be standardized <b>in the same way</b> as the training data for compatibility with the model! That means, we take the mean and standard deviation of the <i>training data</i> to transform also the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.3705455882 83.1160621224\n"
     ]
    }
   ],
   "source": [
    "# NO! we take the same mean and stddev from the training data above!\n",
    "#mean = test_images.mean()\n",
    "#stddev = test_images.std()\n",
    "#print mean, stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_images = (test_images - mean) / stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Images for Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 4000)\n"
     ]
    }
   ],
   "source": [
    "test_images_flat = test_images.reshape(test_images.shape[0],-1)\n",
    "print test_images_flat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/170 [===========================>..] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = model.predict_classes(test_images_flat)\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this TEST SET contains ONLY CARS on images! \n",
    "# Thus all the test classes are 1\n",
    "test_classes = [1] * len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's count the number of ones ...\n",
    "test_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3235294117647059"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = accuracy_score(test_classes, test_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3235294117647059"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55.0/170"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on Test Set is only 32.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "A Convolutional Neural Network (ConvNet or CNN) is a type of (deep) Neural Network that is well-suited for 2D axes data, such as images, as it is optimized for learning from spatial proximity. Its core elements are 2D filter kernels which essentially learn the weights of the Neural Network, and downscaling functions such as Max Pooling.\n",
    "\n",
    "A CNN can have one or more Convolution layers, each of them having an arbitrary number of N filters (which define the depth of the CNN layer), following typically by a pooling step, which groups neighboring pixels together and thus reduces the image resolution by retaining only the maximum values of neighboring pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input\n",
    "\n",
    "Our input to the CNN is the original image array containing all the training images, the standardized version however. We store the shape of the images in the 'input_shape' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 100)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = img_array.shape[1:]  # take all dimensions except the 0th one (which is the number of images)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> input_shape should be (3, 100, 100) \n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=input_shape))\n",
    "#model.add(Activation('relu')) # WAS COMMENTED OUT WHEN WORKED\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2))) # NEW\n",
    "#model.add(Dropout(0.1)) # NEW\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Note: Keras does automatic shape inference.\n",
    "model.add(Dense(256))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# VGG-like convnet:\n",
    "# (from https://keras.io/getting-started/sequential-model-guide/)\n",
    "\n",
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> input_shape should be (3, 100, 100) \n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Note: Keras does automatic shape inference.\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "if output_units > 1:\n",
    "    model.add(Dense(output_units))\n",
    "    model.add(Activation('softmax'))\n",
    "else:\n",
    "    model.add(Dense(1,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we use test data as validation data to see direct results (usually not recommended)\n",
    "validation_data = (test_img, test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multi_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-aa89816ac6f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'categorical_crossentropy'\u001b[0m \u001b[1;31m# multi class\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#optimizer = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# try simpler first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'multi_class' is not defined"
     ]
    }
   ],
   "source": [
    "if multi_class:\n",
    "    loss = 'categorical_crossentropy' # multi class\n",
    "    class_mode='categorical'\n",
    "    #optimizer = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # try simpler first\n",
    "    optimizer = SGD(lr=0.001)\n",
    "else: # binary 0/1\n",
    "    loss = 'binary_crossentropy' \n",
    "    class_mode='binary'\n",
    "    optimizer = 'rmsprop'\n",
    "    #optimizer = RMSprop(lr=0.0001)\n",
    "    #optimizer = 'adam'\n",
    "    #optimizer = SGD(lr=0.001)\n",
    "\n",
    "print \"Class mode:\", class_mode, \", multi_class:\", multi_class\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
