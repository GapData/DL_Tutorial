{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "#from keras.preprocessing import image\n",
    "from progressbar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_and_crop(img,target_width=224,target_height=224):\n",
    "    width, height = img.size\n",
    "    \n",
    "    img_ratio = width / float(height)\n",
    "    target_ratio = target_width / float(target_height)\n",
    "    \n",
    "    # 1) compare ratios and resize the larger side proportional to the target of the smaller side \n",
    "    new_width, new_height = (target_width, target_height)\n",
    "    \n",
    "    if target_ratio > img_ratio:\n",
    "        new_height = int(round(height * (target_width / float(width))))\n",
    "    else:\n",
    "        new_width = int(round(width * (target_height / float(height))))\n",
    "\n",
    "    img_new = img.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "    # The filter argument can be one of NEAREST (use nearest neighbour), BILINEAR (linear interpolation in a \n",
    "    # 2x2 environment), BICUBIC (cubic spline interpolation in a 4x4 environment), or ANTIALIAS (a high-quality downsampling filter).\n",
    "    # If omitted, or if the image has mode \"1\" or \"P\", it is set to NEAREST.\n",
    "    # Note that the bilinear and bicubic filters in the current version of PIL are not well-suited for large downsampling\n",
    "    # ratios (e.g. when creating thumbnails). You should use ANTIALIAS unless speed is much more important than quality.\n",
    "\n",
    "    # 2) crop to target size\n",
    "    # offset to half of the remaining padding (one of them is 0)\n",
    "    width_offset  = (new_width - target_width) / 2\n",
    "    height_offset = (new_height - target_height) / 2\n",
    "    \n",
    "    # crop with offsets\n",
    "    img_new = img_new.crop((width_offset, height_offset, width_offset+target_width, height_offset+target_height))\n",
    "    #  The box is a 4-tuple defining the left, upper, right, and lower pixel coordinate.\n",
    "    return img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 170 files\n"
     ]
    }
   ],
   "source": [
    "path = 'data/CarData/TestImages'\n",
    "files = glob.glob(os.path.join(path, '*.pgm'))\n",
    "print \"Found\", len(files), \"files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "image_names = []\n",
    "\n",
    "for filename in files:\n",
    "    image_names.append(os.path.basename(filename))\n",
    "    with Image.open(filename) as img:\n",
    "        images.append(resize_and_crop(img,target_width=100,target_height=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAAAoCAAAAAAtEwCfAAAIEUlEQVR4nI2V24/dVRXH11r78ruc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\nFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image._ImageCrop image mode=L size=100x40 at 0x7F064AE18910>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAAAoCAAAAAAtEwCfAAAME0lEQVR4nAXBaYyd51UA4HPOu33L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\nwwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image._ImageCrop image mode=L size=100x40 at 0x7F064B10DF10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = '/data/images/monds-persondetect-7k' # base path\n",
    "IMG_PATH = PATH #os.path.join(PATH, 'images')\n",
    "OUT_PATH = os.path.join(PATH, 'thumbs')\n",
    "target_size = (224,224)\n",
    "out_file = os.path.join(OUT_PATH, \"mon_style_persons_cropped_resized_%dx%d.npz\" % (target_size[0], target_size[1]))\n",
    "\n",
    "csv_file = os.path.join(PATH, 'labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filelist contains 7833 files\n"
     ]
    }
   ],
   "source": [
    "image_list = pd.read_csv(csv_file)\n",
    "\n",
    "image_files = list(image_list.image)\n",
    "#image_files = image_list.image.head() # temp to debug\n",
    "print \"Filelist contains\", len(image_files), \"files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (7833 of 7833) |######################| Elapsed Time: 0:09:20 Time: 0:09:20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thumbs = []\n",
    "transpose_for_keras = False\n",
    "pbar = ProgressBar()\n",
    "\n",
    "#for fil in image_files:\n",
    "for fil in pbar(image_files):\n",
    "    img = Image.open(os.path.join(IMG_PATH, fil))\n",
    "    #print img.format, img.size, #img.info\n",
    "    # or use keras.preprocessing.image.load_img (does the some, but handles also grayscale)\n",
    "    \n",
    "    img_new = resize_and_crop(img,target_size[0],target_size[1])\n",
    "    #print img_new.size\n",
    "    \n",
    "    # TODO check if needed: convert opencv-image to keras format \n",
    "    # (note: for keras it depends on TF vs. Theano) -> therefore we keep the order as is and do that later\n",
    "    #img_new = np.swapaxes(np.swapaxes(img_new, 1, 2), 0, 1)[[2,1,1],:,:]\n",
    "    \n",
    "    if transpose_for_keras:\n",
    "        # acc. to Keras application tutorials:\n",
    "        # convert to float32 and order height, width, channel -> channel, height, width\n",
    "        # TODO we dont want to convert to float32 as it makes file size 4x as large\n",
    "        img_new = image.img_to_array(img_new)\n",
    "    else:\n",
    "        # simply convert to numpy\n",
    "        img_new = np.array(img_new)\n",
    "\n",
    "    thumbs.append(img_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert list to np array\n",
    "# will have shape (n_files, 224, 224, 3)\n",
    "\n",
    "thumbs_out = np.array(thumbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to /data/images/monds-persondetect-7k/thumbs/mon_style_persons_cropped_resized_224x224.npz\n"
     ]
    }
   ],
   "source": [
    "# save to NPZ\n",
    "np.savez(out_file, images=thumbs_out, filenames=image_files)\n",
    "print \"Saved to\", out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7833, 224, 224, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thumbs_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thumbs_out.dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
