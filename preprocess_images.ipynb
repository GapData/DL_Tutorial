{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from progressbar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_and_crop(img,target_width=224,target_height=224):\n",
    "    width, height = img.size\n",
    "    \n",
    "    # 1) resize the larger side proportional to the target of the smaller side (will be taller if not same aspect)\n",
    "    new_width, new_height = (target_width, target_height)\n",
    "    \n",
    "    if height > width:\n",
    "        new_height = int(height * (target_width / float(width)))\n",
    "    else:\n",
    "        new_width = int(width * (target_height / float(height)))\n",
    "\n",
    "    img_new = img.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "    # The filter argument can be one of NEAREST (use nearest neighbour), BILINEAR (linear interpolation in a \n",
    "    # 2x2 environment), BICUBIC (cubic spline interpolation in a 4x4 environment), or ANTIALIAS (a high-quality downsampling filter).\n",
    "    # If omitted, or if the image has mode “1” or “P”, it is set to NEAREST.\n",
    "    # Note that the bilinear and bicubic filters in the current version of PIL are not well-suited for large downsampling\n",
    "    # ratios (e.g. when creating thumbnails). You should use ANTIALIAS unless speed is much more important than quality.\n",
    "\n",
    "    # 2) crop to target size\n",
    "    \n",
    "    # offset to half of the remaining padding (one of them is 0)\n",
    "    width_offset  = (new_width - target_width) / 2\n",
    "    height_offset = (new_height - target_height) / 2\n",
    "    width_offset, height_offset\n",
    "    \n",
    "    # crop with offsets\n",
    "    img_new = img_new.crop((width_offset, height_offset, width_offset+target_width, height_offset+target_height))\n",
    "    #  The box is a 4-tuple defining the left, upper, right, and lower pixel coordinate.\n",
    "    return img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = '/data/images/monds-persondetect-7k' # base path\n",
    "IMG_PATH = PATH #os.path.join(PATH, 'images')\n",
    "OUT_PATH = os.path.join(PATH, 'thumbs')\n",
    "target_size = (224,224)\n",
    "out_file = os.path.join(OUT_PATH, \"mon_style_persons_cropped_resized_%dx%d.npz\" % (target_size[0], target_size[1]))\n",
    "\n",
    "csv_file = os.path.join(PATH, 'labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filelist contains 7833 files\n"
     ]
    }
   ],
   "source": [
    "image_list = pd.read_csv(csv_file)\n",
    "\n",
    "image_files = list(image_list.image)\n",
    "#image_files = image_list.image.head() # temp to debug\n",
    "print \"Filelist contains\", len(image_files), \"files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (7833 of 7833) |######################| Elapsed Time: 0:09:20 Time: 0:09:20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thumbs = []\n",
    "transpose_for_keras = False\n",
    "pbar = ProgressBar()\n",
    "\n",
    "#for fil in image_files:\n",
    "for fil in pbar(image_files):\n",
    "    img = Image.open(os.path.join(IMG_PATH, fil))\n",
    "    #print img.format, img.size, #img.info\n",
    "    # or use keras.preprocessing.image.load_img (does the some, but handles also grayscale)\n",
    "    \n",
    "    img_new = resize_and_crop(img,target_size[0],target_size[1])\n",
    "    #print img_new.size\n",
    "    \n",
    "    # TODO check if needed: convert opencv-image to keras format \n",
    "    # (note: for keras it depends on TF vs. Theano) -> therefore we keep the order as is and do that later\n",
    "    #img_new = np.swapaxes(np.swapaxes(img_new, 1, 2), 0, 1)[[2,1,1],:,:]\n",
    "    \n",
    "    if transpose_for_keras:\n",
    "        # acc. to Keras application tutorials:\n",
    "        # convert to float32 and order height, width, channel -> channel, height, width\n",
    "        # TODO we dont want to convert to float32 as it makes file size 4x as large\n",
    "        img_new = image.img_to_array(img_new)\n",
    "    else:\n",
    "        # simply convert to numpy\n",
    "        img_new = np.array(img_new)\n",
    "\n",
    "    thumbs.append(img_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert list to np array\n",
    "# will have shape (n_files, 224, 224, 3)\n",
    "\n",
    "thumbs_out = np.array(thumbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to /data/images/monds-persondetect-7k/thumbs/mon_style_persons_cropped_resized_224x224.npz\n"
     ]
    }
   ],
   "source": [
    "# save to NPZ\n",
    "np.savez(out_file, images=thumbs_out, filenames=image_files)\n",
    "print \"Saved to\", out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7833, 224, 224, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thumbs_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thumbs_out.dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
